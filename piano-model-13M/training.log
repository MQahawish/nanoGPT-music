root - WARNING - step 0: train loss 6.840044, val loss 6.833322, lr 0.000000, mfu -100.00%
root - WARNING - step 250: train loss 2.528511, val loss 2.548559, lr 0.000025, mfu 3.49%
root - WARNING - step 500: train loss 1.881925, val loss 1.911583, lr 0.000050, mfu 3.32%
root - WARNING - step 750: train loss 1.593329, val loss 1.633011, lr 0.000075, mfu 3.12%
root - WARNING - step 1000: train loss 1.447599, val loss 1.504598, lr 0.000100, mfu 2.69%
root - WARNING - step 1250: train loss 1.348496, val loss 1.398607, lr 0.000100, mfu 3.44%
root - WARNING - step 1500: train loss 1.261412, val loss 1.332185, lr 0.000100, mfu 3.46%
root - WARNING - step 1750: train loss 1.208820, val loss 1.287924, lr 0.000100, mfu 3.45%
root - WARNING - step 2000: train loss 1.175506, val loss 1.257404, lr 0.000100, mfu 3.47%
root - WARNING - step 2250: train loss 1.156855, val loss 1.230482, lr 0.000100, mfu 3.47%
root - WARNING - step 2500: train loss 1.124305, val loss 1.211095, lr 0.000100, mfu 3.48%
root - WARNING - step 2750: train loss 1.110950, val loss 1.193661, lr 0.000100, mfu 3.48%
root - WARNING - step 3000: train loss 1.104672, val loss 1.175792, lr 0.000100, mfu 3.47%
root - WARNING - step 3250: train loss 1.084072, val loss 1.163568, lr 0.000099, mfu 3.47%
root - WARNING - step 3500: train loss 1.073964, val loss 1.154162, lr 0.000099, mfu 3.47%
root - WARNING - step 3750: train loss 1.061254, val loss 1.142311, lr 0.000099, mfu 3.47%
root - WARNING - step 4000: train loss 1.051373, val loss 1.127904, lr 0.000099, mfu 3.47%
root - WARNING - step 4250: train loss 1.043113, val loss 1.129595, lr 0.000099, mfu 3.47%
root - WARNING - step 4500: train loss 1.042748, val loss 1.121538, lr 0.000099, mfu 3.47%
root - WARNING - step 4750: train loss 1.034138, val loss 1.115963, lr 0.000099, mfu 3.49%
root - WARNING - step 5000: train loss 1.023896, val loss 1.110021, lr 0.000098, mfu 3.48%
root - WARNING - step 5250: train loss 1.018491, val loss 1.104231, lr 0.000098, mfu 3.48%
root - WARNING - step 5500: train loss 1.012751, val loss 1.098927, lr 0.000098, mfu 3.48%
root - WARNING - step 5750: train loss 1.012147, val loss 1.095843, lr 0.000098, mfu 3.48%
root - WARNING - step 6000: train loss 1.002998, val loss 1.085806, lr 0.000097, mfu 3.48%
root - WARNING - step 6250: train loss 0.993034, val loss 1.087424, lr 0.000097, mfu 3.47%
root - WARNING - step 6500: train loss 0.989036, val loss 1.080364, lr 0.000097, mfu 3.48%
root - WARNING - step 6750: train loss 0.989142, val loss 1.078322, lr 0.000097, mfu 3.48%
root - WARNING - step 7000: train loss 0.980399, val loss 1.082042, lr 0.000096, mfu 3.48%
root - WARNING - step 7250: train loss 0.977971, val loss 1.072153, lr 0.000096, mfu 3.48%
root - WARNING - step 7500: train loss 0.978149, val loss 1.069136, lr 0.000096, mfu 3.48%
root - WARNING - step 7750: train loss 0.968813, val loss 1.067967, lr 0.000095, mfu 3.49%
root - WARNING - step 8000: train loss 0.967110, val loss 1.059914, lr 0.000095, mfu 3.48%
root - WARNING - step 8250: train loss 0.961039, val loss 1.057827, lr 0.000095, mfu 3.48%
root - WARNING - step 8500: train loss 0.958766, val loss 1.057980, lr 0.000094, mfu 3.48%
root - WARNING - step 8750: train loss 0.964137, val loss 1.058080, lr 0.000094, mfu 3.48%
root - WARNING - step 9000: train loss 0.961855, val loss 1.061029, lr 0.000094, mfu 3.48%
root - WARNING - step 9250: train loss 0.957805, val loss 1.052644, lr 0.000093, mfu 3.48%
root - WARNING - step 9500: train loss 0.950306, val loss 1.051935, lr 0.000093, mfu 3.47%
root - WARNING - step 9750: train loss 0.947491, val loss 1.050133, lr 0.000092, mfu 3.48%
root - WARNING - step 10000: train loss 0.943290, val loss 1.049319, lr 0.000092, mfu 3.48%
root - WARNING - step 10250: train loss 0.941600, val loss 1.051663, lr 0.000092, mfu 3.47%
root - WARNING - step 10500: train loss 0.940102, val loss 1.041813, lr 0.000091, mfu 3.48%
root - WARNING - step 10750: train loss 0.934327, val loss 1.042878, lr 0.000091, mfu 3.48%
root - WARNING - step 11000: train loss 0.934281, val loss 1.040688, lr 0.000090, mfu 3.48%
root - WARNING - step 11250: train loss 0.932021, val loss 1.037095, lr 0.000090, mfu 3.49%
root - WARNING - step 11500: train loss 0.928232, val loss 1.042010, lr 0.000089, mfu 3.48%
root - WARNING - step 11750: train loss 0.928510, val loss 1.035635, lr 0.000089, mfu 3.48%
root - WARNING - step 12000: train loss 0.927883, val loss 1.037937, lr 0.000088, mfu 3.48%
root - WARNING - step 12250: train loss 0.931054, val loss 1.040106, lr 0.000088, mfu 3.48%
root - WARNING - step 12500: train loss 0.920074, val loss 1.039437, lr 0.000087, mfu 3.47%
root - WARNING - step 12750: train loss 0.924047, val loss 1.035986, lr 0.000087, mfu 3.48%
root - WARNING - step 13000: train loss 0.915697, val loss 1.031986, lr 0.000086, mfu 3.47%
root - WARNING - step 13250: train loss 0.911094, val loss 1.028148, lr 0.000086, mfu 3.48%
root - WARNING - step 13500: train loss 0.911659, val loss 1.033949, lr 0.000085, mfu 3.48%
root - WARNING - step 13750: train loss 0.917048, val loss 1.026088, lr 0.000084, mfu 3.49%
root - WARNING - step 14000: train loss 0.910318, val loss 1.029208, lr 0.000084, mfu 3.48%
root - WARNING - step 14250: train loss 0.900935, val loss 1.028898, lr 0.000083, mfu 3.47%
root - WARNING - step 14500: train loss 0.905660, val loss 1.031109, lr 0.000083, mfu 3.48%
root - WARNING - step 14750: train loss 0.906177, val loss 1.028576, lr 0.000082, mfu 3.48%
root - WARNING - step 15000: train loss 0.901371, val loss 1.031700, lr 0.000081, mfu 3.48%
root - WARNING - step 15250: train loss 0.900804, val loss 1.029410, lr 0.000081, mfu 3.48%
root - WARNING - step 15500: train loss 0.896590, val loss 1.021654, lr 0.000080, mfu 3.48%
root - WARNING - step 15750: train loss 0.905537, val loss 1.027416, lr 0.000079, mfu 3.48%
root - WARNING - step 16000: train loss 0.894663, val loss 1.025748, lr 0.000079, mfu 3.48%
root - WARNING - step 16250: train loss 0.890365, val loss 1.021697, lr 0.000078, mfu 3.49%
root - WARNING - step 16500: train loss 0.890049, val loss 1.030510, lr 0.000078, mfu 3.48%
root - WARNING - step 16750: train loss 0.896287, val loss 1.025145, lr 0.000077, mfu 3.48%
root - WARNING - step 17000: train loss 0.889248, val loss 1.018204, lr 0.000076, mfu 3.47%
root - WARNING - step 17250: train loss 0.888755, val loss 1.020210, lr 0.000075, mfu 3.48%
root - WARNING - step 17500: train loss 0.883531, val loss 1.017080, lr 0.000075, mfu 3.48%
root - WARNING - step 17750: train loss 0.887114, val loss 1.017733, lr 0.000074, mfu 3.49%
root - WARNING - step 18000: train loss 0.885027, val loss 1.031488, lr 0.000073, mfu 3.48%
root - WARNING - step 18250: train loss 0.886977, val loss 1.026660, lr 0.000073, mfu 3.48%
root - WARNING - step 18500: train loss 0.880097, val loss 1.028799, lr 0.000072, mfu 3.48%
root - WARNING - step 18750: train loss 0.873172, val loss 1.018758, lr 0.000071, mfu 3.48%
root - WARNING - step 19000: train loss 0.883734, val loss 1.019149, lr 0.000071, mfu 3.49%
root - WARNING - step 19250: train loss 0.868952, val loss 1.025225, lr 0.000070, mfu 3.48%
root - WARNING - step 19500: train loss 0.872683, val loss 1.024618, lr 0.000069, mfu 3.48%
root - WARNING - step 19750: train loss 0.873782, val loss 1.029230, lr 0.000068, mfu 3.48%
root - WARNING - step 20000: train loss 0.870024, val loss 1.019631, lr 0.000068, mfu 3.48%
root - WARNING - step 20250: train loss 0.875995, val loss 1.020665, lr 0.000067, mfu 3.48%
root - WARNING - step 20500: train loss 0.869896, val loss 1.015820, lr 0.000066, mfu 3.47%
root - WARNING - step 20750: train loss 0.871172, val loss 1.024099, lr 0.000065, mfu 3.47%
root - WARNING - step 21000: train loss 0.863486, val loss 1.025335, lr 0.000065, mfu 3.47%
root - WARNING - step 21250: train loss 0.870300, val loss 1.024871, lr 0.000064, mfu 3.48%
root - WARNING - step 21500: train loss 0.860602, val loss 1.025999, lr 0.000063, mfu 3.48%
root - WARNING - step 21750: train loss 0.860609, val loss 1.027293, lr 0.000062, mfu 3.47%
root - WARNING - step 22000: train loss 0.858306, val loss 1.016435, lr 0.000062, mfu 3.46%
root - WARNING - step 22250: train loss 0.857009, val loss 1.021351, lr 0.000061, mfu 3.48%
root - WARNING - step 22500: train loss 0.858770, val loss 1.024341, lr 0.000060, mfu 3.48%
root - WARNING - step 22750: train loss 0.856880, val loss 1.025352, lr 0.000059, mfu 3.48%
root - WARNING - step 23000: train loss 0.856771, val loss 1.029019, lr 0.000058, mfu 3.47%
root - WARNING - step 23250: train loss 0.847105, val loss 1.025029, lr 0.000058, mfu 3.48%
root - WARNING - step 23500: train loss 0.853699, val loss 1.021959, lr 0.000057, mfu 3.48%
root - WARNING - step 20500: train loss 0.869503, val loss 1.021326, lr 0.000009, mfu -100.00%
root - WARNING - step 20750: train loss 0.864347, val loss 1.020891, lr 0.000008, mfu 3.48%
root - WARNING - step 21000: train loss 0.856564, val loss 1.018004, lr 0.000008, mfu 3.46%
root - WARNING - step 21250: train loss 0.860233, val loss 1.021635, lr 0.000007, mfu 3.47%
root - WARNING - step 21500: train loss 0.854318, val loss 1.018387, lr 0.000006, mfu 3.48%
root - WARNING - step 21750: train loss 0.859510, val loss 1.018155, lr 0.000005, mfu 3.47%
root - WARNING - step 22000: train loss 0.858101, val loss 1.013680, lr 0.000005, mfu 3.48%
root - WARNING - step 22250: train loss 0.859361, val loss 1.012954, lr 0.000004, mfu 3.47%
root - WARNING - step 22500: train loss 0.856720, val loss 1.020276, lr 0.000004, mfu 3.47%
root - WARNING - step 22750: train loss 0.854140, val loss 1.024675, lr 0.000003, mfu 3.47%
root - WARNING - step 23000: train loss 0.850162, val loss 1.017483, lr 0.000003, mfu 3.46%
root - WARNING - step 23250: train loss 0.858744, val loss 1.015503, lr 0.000002, mfu 3.46%
root - WARNING - step 23500: train loss 0.855591, val loss 1.020635, lr 0.000002, mfu 3.47%
root - WARNING - step 23750: train loss 0.863883, val loss 1.015714, lr 0.000002, mfu 3.46%
root - WARNING - step 24000: train loss 0.853649, val loss 1.013072, lr 0.000001, mfu 3.46%
root - WARNING - step 24250: train loss 0.857740, val loss 1.023028, lr 0.000001, mfu 3.46%
root - WARNING - step 22250: train loss 0.854313, val loss 1.025705, lr 0.000000, mfu -100.00%
root - WARNING - step 22500: train loss 0.853069, val loss 1.012397, lr 0.000000, mfu 3.39%
root - WARNING - step 22750: train loss 0.860519, val loss 1.014534, lr 0.000000, mfu 3.41%
root - WARNING - step 23000: train loss 0.859445, val loss 1.016335, lr 0.000000, mfu 3.41%
root - WARNING - step 23250: train loss 0.855919, val loss 1.017591, lr 0.000000, mfu 3.41%
root - WARNING - step 23500: train loss 0.856188, val loss 1.021486, lr 0.000000, mfu 3.41%
root - WARNING - step 23750: train loss 0.855734, val loss 1.010939, lr 0.000000, mfu 3.41%
root - WARNING - step 24000: train loss 0.859941, val loss 1.021358, lr 0.000000, mfu 3.42%
root - WARNING - step 24250: train loss 0.859047, val loss 1.021281, lr 0.000000, mfu 3.42%
root - WARNING - step 24500: train loss 0.854003, val loss 1.014096, lr 0.000000, mfu 3.42%
root - WARNING - step 24750: train loss 0.858368, val loss 1.013335, lr 0.000000, mfu 3.42%
root - WARNING - step 25000: train loss 0.860586, val loss 1.025236, lr 0.000000, mfu 3.42%
root - WARNING - step 25250: train loss 0.854565, val loss 1.026198, lr 0.000000, mfu 3.42%
root - WARNING - step 25500: train loss 0.861857, val loss 1.018462, lr 0.000000, mfu 3.42%
root - WARNING - step 25750: train loss 0.853448, val loss 1.014187, lr 0.000000, mfu 3.42%
root - WARNING - step 26000: train loss 0.856809, val loss 1.009772, lr 0.000000, mfu 3.41%
root - WARNING - step 26250: train loss 0.859105, val loss 1.015271, lr 0.000000, mfu 3.43%
root - WARNING - step 26500: train loss 0.861721, val loss 1.024277, lr 0.000000, mfu 3.43%
root - WARNING - step 26750: train loss 0.853874, val loss 1.012053, lr 0.000000, mfu 3.42%
root - WARNING - step 27000: train loss 0.856145, val loss 1.014615, lr 0.000000, mfu 3.42%
root - WARNING - step 27250: train loss 0.852839, val loss 1.012064, lr 0.000000, mfu 3.43%
root - WARNING - step 27500: train loss 0.852922, val loss 1.016275, lr 0.000000, mfu 3.43%
root - WARNING - step 27750: train loss 0.858015, val loss 1.015814, lr 0.000000, mfu 3.43%
root - WARNING - step 28000: train loss 0.854187, val loss 1.018312, lr 0.000000, mfu 3.41%
root - WARNING - step 28250: train loss 0.859469, val loss 1.018407, lr 0.000000, mfu 3.40%
root - WARNING - step 28500: train loss 0.859778, val loss 1.006783, lr 0.000000, mfu 3.41%
root - WARNING - step 28750: train loss 0.855622, val loss 1.017223, lr 0.000000, mfu 3.41%
root - WARNING - step 29000: train loss 0.857749, val loss 1.015390, lr 0.000000, mfu 3.41%
root - WARNING - step 29250: train loss 0.860513, val loss 1.008732, lr 0.000000, mfu 3.41%
root - WARNING - step 29500: train loss 0.857745, val loss 1.020099, lr 0.000000, mfu 3.41%
root - WARNING - step 29750: train loss 0.858616, val loss 1.017876, lr 0.000000, mfu 3.41%
root - WARNING - step 30000: train loss 0.858425, val loss 1.010737, lr 0.000000, mfu 3.40%
root - WARNING - step 30250: train loss 0.859162, val loss 1.019170, lr 0.000000, mfu 3.40%
root - WARNING - step 30500: train loss 0.863082, val loss 1.019156, lr 0.000000, mfu 3.39%
root - WARNING - step 30750: train loss 0.855461, val loss 1.015675, lr 0.000000, mfu 3.40%
root - WARNING - step 31000: train loss 0.854478, val loss 1.013221, lr 0.000000, mfu 3.42%
root - WARNING - step 31250: train loss 0.856677, val loss 1.017095, lr 0.000000, mfu 3.42%
root - WARNING - step 31500: train loss 0.857868, val loss 1.015952, lr 0.000000, mfu 3.40%
